{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "160d4d6b-f01c-4678-852a-8bb02dfa7e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm, trange\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "from time import time, ctime, localtime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import models\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split,train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold,  KFold\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "248a8436-8241-4ef9-a72b-3737d1e96351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train dataset is : 68\n",
      "number of test dataset is : 64\n"
     ]
    }
   ],
   "source": [
    "# path = \"D:/SleepDataHallym/\"\n",
    "path = \"/home/nyh/SleepDataSets/\"\n",
    "\n",
    "train_list = glob(path + \"train/*\")\n",
    "print(f\"number of train dataset is : {train_list.__len__()}\")\n",
    "\n",
    "test_list = glob(path + \"test/*\")\n",
    "print(f\"number of test dataset is : {test_list.__len__()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1c587de-827d-452f-b0c7-95ee9531aa9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cae2630-da4d-41cb-a5f8-14d5bc762d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "n = 10\n",
    "arr = list(range(0,10))\n",
    "result = []\n",
    "for i in range(0, n):\n",
    "    comb = combinations(arr, i)\n",
    "    for element in [*comb]:\n",
    "        if element.__len__() != 0 : result.append(element)\n",
    "         # element.__len__() != 1\n",
    "# print(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fe60035-cc0a-476e-b4e1-f7c953af2b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train dataset is : 68\n",
      "number of test dataset is : 64\n"
     ]
    }
   ],
   "source": [
    "# path = \"D:/SleepDataHallym/\"\n",
    "path = \"/home/nyh/SleepDataSets/\"\n",
    "\n",
    "train_list = glob(path + \"train/*\")\n",
    "print(f\"number of train dataset is : {train_list.__len__()}\")\n",
    "\n",
    "test_list = glob(path + \"test/*\")\n",
    "print(f\"number of test dataset is : {test_list.__len__()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08fda533-32df-4d6f-bd86-f8c696f40622",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainDataset(Dataset):\n",
    "    def read_dataset(self):\n",
    "        all_signals_files = []\n",
    "        all_labels = []\n",
    "\n",
    "        for dataset_folder in self.patient_path:\n",
    "            \n",
    "            # print(dataset_folder)\n",
    "            \n",
    "            signals_path = dataset_folder + \"/\"\n",
    "            signals_list = os.listdir(signals_path)\n",
    "            # print(signals_list)\n",
    "            signals_list.sort()\n",
    "            for signals_filename in signals_list:\n",
    "                signals_file = signals_path+signals_filename \n",
    "                all_signals_files.append(signals_file)\n",
    "                all_labels.append(int(signals_filename.split('.npy')[0].split('_')[-1]))\n",
    "                \n",
    "        return all_signals_files, all_labels, len(all_signals_files)\n",
    "    \n",
    "    \n",
    "    def __init__(self, mode, use_rnn, use_channel = [0,1], transform=None, target_transform=None):\n",
    "        # self.path = \"D:/SleepDataHallym/\"\n",
    "        self.path = \"/home/nyh/SleepDataSets/\"\n",
    "        \n",
    "        if mode == \"train\": \n",
    "            self.patient_path = glob(self.path + \"train/*\")\n",
    "            self.patient_list,self.labels,self.length = self.read_dataset()\n",
    "        elif mode == \"test\": \n",
    "            self.patient_path = glob(self.path + \"test/*\")\n",
    "            self.patient_list,self.labels,self.length = self.read_dataset()\n",
    "        else: return -1\n",
    "\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.signal = []\n",
    "        self.annotation = []\n",
    "        self.use_rnn = use_rnn\n",
    "        self.use_channel = use_channel\n",
    "        \n",
    "    def __len__(self):\n",
    "        # print(len(self.patient_list))\n",
    "        return len(self.patient_list)\n",
    "    \n",
    "    def print_line(cnt, folder_name):\n",
    "        print(f\"{cnt}th file name is {folder_name[-6:]} patient collect\", end= \"\\t\\t\")\n",
    "\n",
    "        if cnt%3 == 0:\n",
    "            print()\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        if self.use_rnn == True:\n",
    "            folder_name = '/'.join(self.patient_list[index].split('/')[:-1]) + '/'\n",
    "            folder_list = os.listdir(folder_name)\n",
    "            folder_list.sort()\n",
    "            folder_length = len(folder_list)-1\n",
    "            \n",
    "            # train/patient_num_OSA/current_epoch\n",
    "            current_epoch = int(self.patient_list[index].split('/')[-1].split('_')[0]) \n",
    "            start_index, end_index = current_epoch - 2, current_epoch + 3             \n",
    "\n",
    "            labels = int(folder_list[current_epoch].split('.npy')[0].split('_')[-1])\n",
    "            \n",
    "            signals = None\n",
    "            input_signals = None\n",
    "            \n",
    "            count = 0\n",
    "            for i in range(start_index,end_index):\n",
    "                if i <= 0:\n",
    "                    c_signals = np.load(folder_name+folder_list[0])\n",
    "                    c_signals = c_signals[self.use_channel,:]             \n",
    "                    input_signals = torch.Tensor(c_signals)\n",
    "\n",
    "                elif i >= folder_length:\n",
    "                    c_signals = np.load(folder_name+folder_list[folder_length])\n",
    "                    c_signals = c_signals[self.use_channel,:]\n",
    "                    input_signals = torch.Tensor(c_signals)\n",
    "                else:\n",
    "                    c_signals = np.load(folder_name+folder_list[i])\n",
    "                    c_signals = c_signals[self.use_channel,:]\n",
    "                    input_signals = torch.Tensor(c_signals)\n",
    "                    \n",
    "                input_signals = input_signals.reshape(1, self.use_channel.__len__(), 6000)\n",
    "                \n",
    "                if count == 0:\n",
    "                    signals = input_signals\n",
    "\n",
    "                else:\n",
    "                    # print(signals, type(signals))\n",
    "                    signals = torch.cat((signals, input_signals), 0)\n",
    "\n",
    "                count += 1\n",
    "                        \n",
    "                # print(signals.shape, labels)\n",
    "                # print(input_signals.shape)\n",
    "\n",
    "            return signals, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6977037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler # 실습 때 사용하였던 SubsetRandomSampler 사용\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "train_list = CustomTrainDataset(mode = \"train\", use_rnn = True,  use_channel = [2,3,4,6])\n",
    "test_list = CustomTrainDataset(mode = \"test\", use_rnn = True,  use_channel = [2,3,4,6])\n",
    "\n",
    "train_size = 0.8 # train size 0.9 , validation size = 0.1\n",
    "num_train = train_list.__len__() # train_data의 크기를 저장 \n",
    "indices = list(range(num_train)) # train_Data 크기에 맞는 인덱스 생성 \n",
    "np.random.shuffle(indices)   #  인덱스를 섞어야 라벨과 데이터가 안섞임\n",
    "split = int(np.floor(train_size * num_train)) # 학습 데이터의 비율과 총 데이터의 크기를 곱한다음 np.floor를 통해 버림을 합니다.\n",
    "train_idx, valid_idx = indices[:split], indices[split:] # 이제 split 된 크기만큼 train과 validation 데이터 셋을 나눠 줍니다. \n",
    " # 이제 나눈 인덱스의 번호로 SubsetSampler를 통해 넣어줍니다\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a902b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49265"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b1b02a-935f-49a0-b4df-747298386006",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset=train_list,batch_size=64, sampler= train_sampler, num_workers = 2)\n",
    "validloader = DataLoader(dataset=train_list,batch_size=64, sampler= valid_sampler, num_workers = 2)\n",
    "testloader = DataLoader(dataset=test_list,batch_size=64, shuffle=True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0841a555-e33a-4ee0-b890-0e614c541e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class DeepSleepNet(nn.Module):\n",
    "    def __init__(self, in_channel = 4, small_Fs = 8, big_Fs = 6, Fs = 200):\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "        \n",
    "        if torch.cuda.is_available(): self.use_gpu = True\n",
    "        else: self.use_gpu = False\n",
    "        self.num_directions = 2 #  bidirctionalLSTM \n",
    "        self.num_layers = 1\n",
    "        self.hidden_dim = 512\n",
    "        \n",
    "\n",
    "\n",
    "        self.smallCNN = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = in_channel, out_channels = 64 , kernel_size = Fs//2 , stride = Fs//16, padding = Fs//2//2, bias = False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.MaxPool1d(kernel_size = 8, stride = 8,  padding = 4),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Conv1d(in_channels = 64 , out_channels = 128 , kernel_size = small_Fs, \n",
    "                        stride = 1, padding= small_Fs//2, bias = False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv1d(in_channels = 128 , out_channels = 128 , kernel_size = small_Fs, \n",
    "                        stride = 1, padding = small_Fs//2, bias = False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv1d(in_channels = 128 , out_channels = 128 , kernel_size = small_Fs, \n",
    "                        stride = 1, padding= small_Fs//2, bias = False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.MaxPool1d(kernel_size = 4, stride = 4,  padding = 2)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.bigCNN = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = in_channel, out_channels = 64 , kernel_size = Fs*4 , stride = Fs//2, padding = Fs*4//2, bias = False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.MaxPool1d(kernel_size = 4, stride = 4,  padding = 2), # padding = filter_size//2\n",
    "            nn.Dropout(0.5) ,\n",
    "\n",
    "            nn.Conv1d(in_channels = 64 , out_channels = 128 , kernel_size = big_Fs, stride = 1, padding= big_Fs//2, bias = False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv1d(in_channels = 128 , out_channels = 128 , kernel_size = big_Fs, stride = 1, padding= big_Fs//2, bias = False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv1d(in_channels = 128 , out_channels = 128 , kernel_size = big_Fs, stride = 1, padding= big_Fs//2, bias = False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.MaxPool1d(kernel_size = 2, stride = 2,  padding = 1)\n",
    "        )\n",
    "\n",
    "        self.lstm_layer1 = nn.LSTM(1280 + 2176, 512, bidirectional = True)\n",
    "        self.lstm_layer2 = nn.LSTM(512 * 2, 512, bidirectional = True)\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Linear(1280 + 2176, 1024)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 6)  # big and small conv concat     \n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(p = 0.5)\n",
    "\n",
    "    def init_hidden1(self, order_signal):\n",
    "        # first = h(hidden) / second = c(cell)\n",
    "        if self.use_gpu:\n",
    "            return (\n",
    "            Variable(torch.zeros(self.num_directions * self.num_layers, order_signal, self.hidden_dim).cuda()),  # hidden\n",
    "            Variable(torch.zeros(self.num_directions * self.num_layers, order_signal, self.hidden_dim).cuda()))  # cell\n",
    "        else:\n",
    "            return (Variable(torch.zeros(self.num_directions * self.num_layers, order_signal, self.hidden_dim)),  # hidden\n",
    "                    Variable(torch.zeros(self.num_directions * self.num_layers, order_signal, self.hidden_dim)))  # cell\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_output = None\n",
    "        order_signal = x.shape[1]\n",
    "        \n",
    "        for i in range(order_signal):\n",
    "            # print(x.shape)\n",
    "            cnn = x[:, i, :, :]\n",
    "            # print(cnn.shape)\n",
    "            small = self.smallCNN(cnn)\n",
    "            big = self.bigCNN(cnn)\n",
    "\n",
    "            feature_big = torch.flatten(big, 1)\n",
    "            feature_small = torch.flatten(small, 1)  # (batch, channel)\n",
    "\n",
    "            cnn_output = torch.cat((feature_big, feature_small), dim=1)\n",
    "            \n",
    "            if i == 0:\n",
    "                lstm_output = cnn_output\n",
    "            else:\n",
    "                lstm_output = torch.cat((lstm_output, cnn_output), 1)\n",
    "        \n",
    "        \n",
    "        batch_size = lstm_output.size(0)\n",
    "        lstm_output = lstm_output.reshape(batch_size, -1, 1280+2176) # Afer concat, We got [batchsize , 5 * (1280 + 2176)] -> we append 2 startindex and endindex 3\n",
    "\n",
    "        self.hidden1 = self.init_hidden1(order_signal)\n",
    "        output, self.hidden1 = self.lstm_layer1(lstm_output, self.hidden1)\n",
    "\n",
    "        lstm_output = self.dropout(lstm_output)\n",
    "        lstm_shortcut = self.shortcut(lstm_output)\n",
    "        \n",
    "        lstm_output, _ = self.lstm_layer1(lstm_output)\n",
    "        lstm_output = self.dropout(lstm_output)\n",
    "        lstm_output, _ = self.lstm_layer2(lstm_output)\n",
    "        lstm_output = self.dropout(lstm_output)\n",
    "\n",
    "        lstm_output = torch.add(lstm_output, lstm_shortcut)\n",
    "        output = self.dropout(lstm_output)\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return(output[:, 2, :]) # return middel signal classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f3d88a2-1420-46ee-a606-8f57d382aa80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Start Learning =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3ce8e16395489a8d029a3bc6e236d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262184dc1a484e64a97f0476190e4d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f69539cd28416f9e7613baa698f9fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/154 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93856f0cce0b4378b1a78c89890d6038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/724 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100.. Train loss: 1.375.. Train acc: 0.580.. val loss: 0.462.. val accuracy: 0.846test loss: 0.462.. test accuracy: 0.846\n",
      "Validation loss decreased (inf --> 0.461937).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f808efc0cebb43cbbdb0f30b4aae7689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb61c4ac505640d6b456763db2232084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/154 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab248ebbdc0415e8ccf8d28b4e253b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/724 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100.. Train loss: 0.742.. Train acc: 0.711.. val loss: 0.498.. val accuracy: 0.827test loss: 0.498.. test accuracy: 0.827\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea9c4a323c3462c86d6b8aa8363ece7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0307230a2ba54065a141c1caf0d0037f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/154 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea72b903d324b4da0a9d0bd2fd6d665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/724 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100.. Train loss: 0.669.. Train acc: 0.739.. val loss: 0.543.. val accuracy: 0.788test loss: 0.543.. test accuracy: 0.788\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d91331fc1b946229ce7f3c3ab7dc247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb5c5034e98478eb57ddc74a7285d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/154 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c463cda94f5c457e8586c200c0839872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/724 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "from sched import scheduler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "epochs = 100 # 반복 수는 100\n",
    "batch_size= 64\n",
    "cnt = 0      # early stopping을 적용하기 위해 만들어놓은 cnt\n",
    "\n",
    "# train 및 val Loss 저장 \n",
    "train_loss = torch.zeros(epochs)\n",
    "val_loss = torch.zeros(epochs)\n",
    "test_loss = torch.zeros(epochs)\n",
    "\n",
    "# train 및 val Accuracy 저장 \n",
    "train_acc = torch.zeros(epochs)\n",
    "val_acc = torch.zeros(epochs)\n",
    "test_acc = torch.zeros(epochs)\n",
    "\n",
    "# 초기 Loss값은 무한대\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "# epochs 수만큼 학습 진행\n",
    "print(\"===== Start Learning =====\")\n",
    "\n",
    "model = DeepSleepNet()\n",
    "\n",
    "if torch.cuda.device_count() > 1: # GPU가 2개 이상이라면\n",
    "    model = nn.DataParallel(model) # nn.DataParallel을 사용하여 GPU 병렬 처리 진행\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas = [0.9, 0.999]) # 기본적인 Adam 사용 후 lr 및 Optimizier 변경 예정\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    \n",
    "    model.train()\n",
    "    for inputs, labels in tqdm(trainloader, leave=True):    \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad() # optimizer 초기화 -> 모든 gradient를 초기화 시켜줌으로써 이전에 사용했던 기울기에 더해지지않고 새로 구하게 됨\n",
    "        logits = model.forward(inputs) # validation set인 input값을 넣어서 실행       \n",
    "        loss = criterion(logits, labels) # criterion은 이전에 정의한 CrossEntropy를 통해 Loss 계산\n",
    "        loss.backward() # backward를 통해 역전파 실행 계산된 loss를 가지고 모델의 파라미터 개선\n",
    "        optimizer.step() # optimizer.step()을 통해 개선된 파라미터 적용\n",
    "\n",
    "        train_loss[epoch] += loss.item() # 에포크당 train_loss 누적\n",
    "\n",
    "        ps = F.softmax(logits, dim=1) # softmax함수를 통한 정규화 (0 ~ 1) 사이의 확률로 만들어줌\n",
    "        top_p, top_class = ps.topk(1, dim=1) # topk를 통해 가장 높은 한개를 뽑음\n",
    "\n",
    "        equals = top_class == labels.reshape(top_class.shape)   # 일치하는지 확인.\n",
    "        train_acc[epoch] += torch.mean(equals.type(torch.FloatTensor)).item()  # 정확도 계산을 위해 float로 타입 변환 후 mean 계산.\n",
    "\n",
    "    # Loss의 평균을 구하기\n",
    "    train_loss[epoch] /= len(trainloader)\n",
    "    train_acc[epoch] /= len(trainloader)\n",
    "    \n",
    "    model.eval()   #dropout Layer와 BatchNormLayer는 eval과정에서 필요하지 않기 때문\n",
    "    with torch.no_grad():  # validation 과정 no_grad()를 통해 Gradient 계산 안함.\n",
    "        # validloder에 넣어둔 값 들고오기\n",
    "\n",
    "        for inputs, labels in tqdm(validloader, leave=True):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # 위에서 train 후 validation 실행. train한번 당 validation 1번 실행.\n",
    "\n",
    "            logits = model.forward(inputs) # validation set인 input값을 넣어서 실행 \n",
    "            batch_loss = criterion(logits, labels).detach() # validation set의 Loss 계산\n",
    "            val_loss[epoch] += batch_loss.item() # Loss 값 누적\n",
    "\n",
    "            # Calculate accuracy\n",
    "            ps = F.softmax(logits, dim=1) # 확률값 구하기 (0~1) 사이로 정규화가 됨\n",
    "            top_p, top_class = ps.topk(1, dim=1) # 가장 높은값 하나를 고르는데 그 값과 idx가져옴\n",
    "            equals = top_class == labels.view(*top_class.shape) # 일치하는지 확인 \n",
    "            val_acc[epoch] += torch.mean(equals.type(torch.FloatTensor)).item() # # 정확도 계산을 위해 float로 타입 변환 후 mean 계산.\n",
    "\n",
    "        # validation Loss 및 accuracy 평균냄\n",
    "        val_loss[epoch] /= len(validloader)\n",
    "        val_acc[epoch] /= len(validloader)\n",
    "    \n",
    "    ####### Test ######\n",
    "    with torch.no_grad():  # validation 과정 no_grad()를 통해 Gradient 계산 안함.\n",
    "        # validloder에 넣어둔 값 들고오기\n",
    "\n",
    "        for inputs, labels in tqdm(testloader, leave=True):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # 위에서 train 후 validation 실행. train한번 당 validation 1번 실행.\n",
    "\n",
    "\n",
    "            logits = model.forward(inputs) # validation set인 input값을 넣어서 실행 \n",
    "            batch_loss = criterion(logits, labels).detach() # validation set의 Loss 계산\\\n",
    "            test_loss[epoch] += batch_loss.item() # Loss 값 누적\n",
    "\n",
    "            # Calculate accuracy\n",
    "            ps = F.softmax(logits, dim=1) # 확률값 구하기 (0~1) 사이로 정규화가 됨\n",
    "            top_p, top_class = ps.topk(1, dim=1) # 가장 높은값 하나를 고르는데 그 값과 idx가져옴\n",
    "            equals = top_class == labels.view(*top_class.shape) # 일치하는지 확인 \n",
    "            test_acc[epoch] += torch.mean(equals.type(torch.FloatTensor)).item() # # 정확도 계산을 위해 float로 타입 변환 후 mean 계산.\n",
    "\n",
    "        # validation Loss 및 accuracy 평균냄\n",
    "        test_loss[epoch] /= len(testloader)\n",
    "        test_acc[epoch] /= len(testloader)\n",
    "\n",
    "    ##################### PRINT LOSS & ACC #####################\n",
    "    print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "          f\"Train loss: {train_loss[epoch]:.3f}.. \"\n",
    "          f\"Train acc: {train_acc[epoch]:.3f}.. \"\n",
    "          f\"val loss: {val_loss[epoch]:.3f}.. \"\n",
    "          f\"val accuracy: {val_acc[epoch]:.3f}.. \"\n",
    "          f\"test loss: {test_loss[epoch]:.3f}.. \"\n",
    "          f\"test accuracy: {test_acc[epoch]:.3f}.. \"\n",
    "         )\n",
    "\n",
    "    ##################### 최적의 모델 저장 #####################\n",
    "    if val_loss[epoch] <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        val_loss[epoch]))\n",
    "        torch.save(model.module.state_dict(), 'model_best_channel_2346.pt')\n",
    "        valid_loss_min = val_loss[epoch]\n",
    "\n",
    "        # 가장 낮은 Loss값을 가지게 된다면 Early Stopping count 초기화\n",
    "        cnt = 0\n",
    "\n",
    "    # 20번 이상 Loss 개선이 안된다면 종료\n",
    "    ############# Early Stopping #############\n",
    "    if cnt >= 10:\n",
    "        print(\"Early Stopping\")\n",
    "        break\n",
    "\n",
    "    cnt+=1 #Loss 개선 실패\n",
    "    ########################################################\n",
    "    scheduler.step()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a523b3af-e732-4c40-89fc-e31e1e33f96d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d07dbf3-545a-42b9-91fd-370bb716fc15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('nyh')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6294b4ef0e4c52c7a2802844b3dd361f2afc0517f08f729f87f8b6d38982a606"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
